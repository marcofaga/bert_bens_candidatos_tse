modelo <- multinom_reg() %>%
set_engine("nnet", MaxNWts = 2000) %>%
set_mode("classification")
# Criar um workflow que une a receita e o modelo
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(modelo)
# Treinar o modelo com os dados de treino
fit_model <- wf %>% fit(data = train_data)
# Fazer previsões no conjunto de teste
predictions <- predict(fit_model, test_data) %>%
bind_cols(test_data)
# Avaliar o desempenho utilizando métricas (por exemplo, acurácia)
metrics <- metrics(predictions, truth = cat, estimate = .pred_class)
print(metrics)
# Criar uma receita para o pré-processamento do texto
rec <- recipe(cat ~ ds_bem_arrum, data = train_data) %>%
# Tokenizar o texto
step_tokenize(ds_bem_arrum) %>%
# Remover stopwords em português
step_stopwords(ds_bem_arrum, custom_stopword_source = stop) %>%
# Filtrar tokens menos frequentes para reduzir dimensionalidade
step_tokenfilter(ds_bem_arrum, max_tokens = 1000) %>%
# Converter para uma representação TF-IDF
step_tfidf(ds_bem_arrum)
# Especificar o modelo de regressão logística multinomial com o engine 'nnet'
modelo <- multinom_reg() %>%
set_engine("nnet", MaxNWts = 2000) %>%
set_mode("classification")
# Criar um workflow que une a receita e o modelo
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(modelo)
# Treinar o modelo com os dados de treino
fit_model <- wf %>% fit(data = train_data)
# Especificar o modelo de regressão logística multinomial com o engine 'nnet'
modelo <- multinom_reg() %>%
set_engine("nnet", MaxNWts = 10000) %>%
set_mode("classification")
# Criar um workflow que une a receita e o modelo
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(modelo)
# Treinar o modelo com os dados de treino
fit_model <- wf %>% fit(data = train_data)
# Fazer previsões no conjunto de teste
predictions <- predict(fit_model, test_data) %>%
bind_cols(test_data)
# Avaliar o desempenho utilizando métricas (por exemplo, acurácia)
metrics <- metrics(predictions, truth = cat, estimate = .pred_class)
print(metrics)
# Criar uma receita para o pré-processamento do texto
rec <- recipe(cat ~ ds_bem_arrum, data = train_data) %>%
# Tokenizar o texto
step_tokenize(ds_bem_arrum) %>%
# Remover stopwords em português
step_stopwords(ds_bem_arrum, custom_stopword_source = stop) %>%
# Filtrar tokens menos frequentes para reduzir dimensionalidade
step_tokenfilter(ds_bem_arrum, max_tokens = 500) %>%
# Converter para uma representação TF-IDF
step_tfidf(ds_bem_arrum)
# Especificar o modelo de regressão logística multinomial com o engine 'nnet'
modelo <- multinom_reg() %>%
set_engine("nnet", MaxNWts = 10000) %>%
set_mode("classification")
# Criar um workflow que une a receita e o modelo
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(modelo)
# Treinar o modelo com os dados de treino
fit_model <- wf %>% fit(data = train_data)
# Fazer previsões no conjunto de teste
predictions <- predict(fit_model, test_data) %>%
bind_cols(test_data)
# Avaliar o desempenho utilizando métricas (por exemplo, acurácia)
metrics <- metrics(predictions, truth = cat, estimate = .pred_class)
print(metrics)
predictions
# Carregar o dataset (supondo que o arquivo seja 'seu_arquivo.csv')
data <-
read_parquet("bases/bd01_benscand_treino.parquet") |>
mutate(cat = as.factor(categoria_cepesp)) |>
select(ds_bem_arrum, cat) #|>
# Dividir os dados em treino (80%) e teste (20%), estratificando pela variável 'tipo'
set.seed(123)
data_split <- initial_split(data, prop = 0.8, strata = cat)
train_data <- training(data_split)
test_data  <- testing(data_split)
# Arrumando os acentos da stopwords
stop <- stopwords::stopwords("pt")
stop <- stri_trans_general(stop, "Latin-ASCII")
# Criar uma receita para o pré-processamento do texto
rec <- recipe(cat ~ ds_bem_arrum, data = train_data) %>%
# Tokenizar o texto
step_tokenize(ds_bem_arrum) %>%
# Remover stopwords em português
step_stopwords(ds_bem_arrum, custom_stopword_source = stop) %>%
# Filtrar tokens menos frequentes para reduzir dimensionalidade
step_tokenfilter(ds_bem_arrum, max_tokens = 500) %>%
# Converter para uma representação TF-IDF
step_tfidf(ds_bem_arrum)
# Especificar o modelo de regressão logística multinomial com o engine 'nnet'
modelo <- multinom_reg() %>%
set_engine("nnet", MaxNWts = 10000) %>%
set_mode("classification")
# Criar um workflow que une a receita e o modelo
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(modelo)
# Treinar o modelo com os dados de treino
fit_model <- wf %>% fit(data = train_data)
Sys.time()
beep(3)
# Fazer previsões no conjunto de teste
predictions <- predict(fit_model, test_data) %>%
bind_cols(test_data)
beep(3)
# Avaliar o desempenho utilizando métricas (por exemplo, acurácia)
metrics <- metrics(predictions, truth = cat, estimate = .pred_class)
print(metrics)
# Supondo que seu workflow treinado esteja na variável `modelo_treinado`
saveRDS(fit_model, "modelo/mod01_regressao_multinomial.rds")
View(predictions)
apx <- read_parquet("output/base_testando.parquet")
library(tidyverse)
library(beepr)
library(janitor)
library(arrow)
library(stringi)
library(tidymodels)
library(textrecipes)
library(tidytext)
apx <- read_parquet("output/base_testando.parquet")
View(apx)
apx <- read_parquet("output/base_testando.parquet")
apx <- read_parquet("output/base_testando.parquet")
View(apx)
apx$erro <- apx$y == apx$y_pred
View(apx)
apx <- read_parquet("output/base_testando.parquet")
apx$erro <- apx$y == apx$y_pred
View(apx)
summary(apx$erro)
506/10000
9494 /10000
apx <- apx |> filter(ds_bem_candidato != "#NULO")
summary(apx$erro)
9422/9847
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
bens2 <- bens
bens <- clean_names(bens)
bens$y <- as.numeric(as.factor(bens$categoria_cepesp))
bens$y
bens_treino <- bens |> filter(!is.na(y))
bens_apply <- bens |> filter(is.na(y))
View(bens)
View(bens_treino)
bens_treino$y
bens_treino$y <- bens_treino$y - 1
bens_treino$y
write_parquet(bens_treino, "bases/bd01_benscand_treino.parquet")
write_parquet(bens_apply, "bases/bd01_benscand_apply.parquet")
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
library(tidyverse)
library(beepr)
library(janitor)
library(arrow)
library(stringi)
library(tidymodels)
library(textrecipes)
library(tidytext)
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
bens2 <- bens
bens <- clean_names(bens)
bens$y <- as.numeric(as.factor(bens$categoria_cepesp))
bens_treino <- bens |> filter(!is.na(y))
bens_apply <- bens |> filter(is.na(y))
bens_treino$y <- bens_treino$y - 1
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
beep(3)
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
beep(3)
View(bens)
bens$DS_BEM_CANDIDATO_2 <- bens$DS_BEM_CANDIDATO
bens$id <- c(1:nrow(bens))
bens$id
View(bens)
bens$DS_BEM_CANDIDATO_2 <- bens$DS_BEM_CANDIDATO
bens$DS_BEM_CANDIDATO_2[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
bens$TIPO_ARRUMADO[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
bens$DS_TIPO_BEM_CANDIDATO[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
bens$DS_BEM_CANDIDATO_2[bens$DS_BEM_CANDIDATO_2 == "#NULO"] <- bens$DS_TIPO_BEM_CANDIDATO[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
View(bens)
bens <- clean_names(bens)
bens$y <- as.numeric(as.factor(bens$categoria_cepesp))
bens_treino <- bens |> filter(!is.na(y))
bens_apply <- bens |> filter(is.na(y))
bens_treino$y <- bens_treino$y - 1
bens_treino$y
unique(bens_treino$y)
write_parquet(bens_treino, "bases/bd01_benscand_treino.parquet")
write_parquet(bens_apply, "bases/bd01_benscand_apply.parquet")
View(bens_treino)
View(bens_apply)
library(tidyverse)
library(beepr)
library(janitor)
library(arrow)
library(stringi)
library(tidymodels)
library(textrecipes)
library(tidytext)
## A02 - BERT ==================================================================
apx <- read_parquet("bases/bd01_benscand_treino.parquet")
View(apx)
apsplit <- strsplit(apx$ds_bem_candidato_2)
apsplit <- strsplit(apx$ds_bem_candidato_2, " ")
apsplit <- map(apsplit, ~length(.))
apsplit
apsplit <- unlist(apsplit)
apsplit
apsplit <- max(unlist(apsplit))
apsplit
apsplit <- strsplit(apx$ds_bem_candidato_2, " ")
apsplit <- map(apsplit, ~length(.))
apsplit <- unlist(apsplit)
which(apsplit == 184)
View(apx[2402233,])
ap2 <- apx[2402233,]
ap2$ds_bem_candidato_2
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
bens$id <- c(1:nrow(bens))
bens$DS_BEM_CANDIDATO_2 <- bens$DS_BEM_CANDIDATO
bens$DS_BEM_CANDIDATO_2[bens$DS_BEM_CANDIDATO_2 == "#NULO"] <- bens$DS_TIPO_BEM_CANDIDATO[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
bens$DS_BEM_CANDIDATO_2 <- trimws(bens$DS_BEM_CANDIDATO_2)
bens <- clean_names(bens)
bens$y <- as.numeric(as.factor(bens$categoria_cepesp))
bens_treino <- bens |> filter(!is.na(y))
bens_apply <- bens |> filter(is.na(y))
bens_treino$y <- bens_treino$y - 1
write_parquet(bens_treino, "bases/bd01_benscand_treino.parquet")
write_parquet(bens_apply, "bases/bd01_benscand_apply.parquet")
## A02 - BERT ==================================================================
apx <- read_parquet("bases/bd01_benscand_treino.parquet")
apsplit <- strsplit(apx$ds_bem_candidato_2, " ")
apsplit <- map(apsplit, ~length(.))
apsplit <- unlist(apsplit)
summary(apsplit)
which(apsplit == 125)
View(apx[2227162 ,])
ap <- apx[2227162 ,]
gsub("\\n", " ", ap$ds_bem_candidato_2)
gsub("\n", " ", ap$ds_bem_candidato_2)
gsub("\\\\n", " ", ap$ds_bem_candidato_2)
gsub("\n", " ", ap$ds_bem_candidato_2)
gsub("\\s+", " ", ap$ds_bem_candidato_2)
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
select(ANO_ELEICAO,
DS_TIPO_BEM_CANDIDATO,
DS_BEM_CANDIDATO,
VR_BEM_CANDIDATO) |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp[bens$ANO_ELEICAO == 2006] <- NA
bens$id <- c(1:nrow(bens))
bens$DS_BEM_CANDIDATO_2 <- bens$DS_BEM_CANDIDATO
bens$DS_BEM_CANDIDATO_2[bens$DS_BEM_CANDIDATO_2 == "#NULO"] <- bens$DS_TIPO_BEM_CANDIDATO[bens$DS_BEM_CANDIDATO_2 == "#NULO"]
bens$DS_BEM_CANDIDATO_2 <- trimws(bens$DS_BEM_CANDIDATO_2)
bens$DS_BEM_CANDIDATO_2 <- gsub("\\s+", " ", bens$DS_BEM_CANDIDATO_2)
apsplit <- strsplit(bens$DS_BEM_CANDIDATO_2, " ")
apsplit <- map(apsplit, ~length(.))
apsplit <- unlist(apsplit)
summary(apsplit)
which(apsplit == 94)
View(bens[which(apsplit == 94),])
bens <- clean_names(bens)
bens$y <- as.numeric(as.factor(bens$categoria_cepesp))
bens_treino <- bens |> filter(!is.na(y))
bens_apply <- bens |> filter(is.na(y))
bens_treino$y <- bens_treino$y - 1
write_parquet(bens_treino, "bases/bd01_benscand_treino.parquet")
write_parquet(bens_apply, "bases/bd01_benscand_apply.parquet")
library(tidyverse)
library(beepr)
library(janitor)
library(arrow)
library(stringi)
library(tidymodels)
library(textrecipes)
library(tidytext)
apx <- read_parquet("output/base_testando.parquet")
apx$y == apx$y_pred
apx$erro <- apx$y == apx$y_pred
View(apx)
## A02 - BERT ==================================================================
apx <- read_parquet("bases/bd01_benscand_treino.parquet")
View(apx)
apx <- read_parquet("output/base_testando.parquet")
View(apx)
apx$erro <- apx$y == apx$y_pred
View(apx)
apx <- read_parquet("output/base_testando.parquet")
apx$categoria_cepesp_pred <- apx$categoria_cepesp[match(apx$y_pred, apx$y)])]
apx$categoria_cepesp_pred <- apx$categoria_cepesp[match(apx$y_pred, apx$y)]
View(apx)
apx$erro <- apx$y == apx$y_pred
View(apx)
summary(apx$erro)
9587/1000
9587/10000
apx <- read_parquet("output/base_final_2006_2008.parquet")
View(apx)
apx1 <- read_parquet("output/base_testando.parquet")
apx$categoria_cepesp_pred <- apx1$categoria_cepesp[match(apx$y_pred, apx1$y)]
View(apx)
summary(apx$categoria_cepesp_pred)
summary(as.factor(apx$categoria_cepesp_pred))
library(tidyverse)
library(beepr)
library(janitor)
library(arrow)
library(stringi)
library(tidymodels)
library(textrecipes)
library(tidytext)
library(digest)
apx <- read_parquet("output/base_final_2006_2008.parquet")
apx1 <- read_parquet("output/base_testando.parquet")
apx$categoria_cepesp_bert <- apx1$categoria_cepesp[match(apx$y_pred, apx1$y)]
apx2 <- read_parquet("output/base_final_2010_2022.parquet")
apx2$categoria_cepesp_bert <- apx1$categoria_cepesp[match(apx2$y_pred, apx1$y)]
files <- list.files("raw", full.names = T, pattern = "parquet")
df <- open_dataset(files)
bens <-
df |>
collect() |>
arrange(ANO_ELEICAO)
bens$tipo_arrumado <- tolower(bens$DS_TIPO_BEM_CANDIDATO)
bens$tipo_arrumado <- stri_trans_general(bens$tipo_arrumado, "Latin-ASCII")
tipos <-
bens |>
group_by(ANO_ELEICAO, tipo_arrumado) |>
summarise(n = n()) |>
filter(ANO_ELEICAO >= 2010)
categoria1 <- read_csv("raw/primeira_categorizacao.csv") |> clean_names()
bens$categoria_cepesp_manual <- categoria1$classificacao_sugerida[match(bens$tipo_arrumado, categoria1$categorias_fornecidas)]
bens$categoria_cepesp_manual[bens$ANO_ELEICAO == 2008] <- NA
bens$categoria_cepesp_manual[bens$ANO_ELEICAO == 2006] <- NA
bens$id <- c(1:nrow(bens))
bens$DS_BEM_CANDIDATO_CEPESP <- bens$DS_BEM_CANDIDATO
bens$DS_BEM_CANDIDATO_CEPESP[bens$DS_BEM_CANDIDATO_CEPESP == "#NULO"] <- bens$DS_TIPO_BEM_CANDIDATO[bens$DS_BEM_CANDIDATO_CEPESP == "#NULO"]
bens$DS_BEM_CANDIDATO_CEPESP <- trimws(bens$DS_BEM_CANDIDATO_CEPESP)
bens$DS_BEM_CANDIDATO_CEPESP <- gsub("\\s+", " ", bens$DS_BEM_CANDIDATO_CEPESP)
benscat_bert <- apx |> select(id, ds_bem_candidato_2, categoria_cepesp_bert)
apx2 <- apx2 |> select(-y_pred)
benscat_bert <- rbind(benscat_bert, apx2)
bens$categoria_cepesp_bert <- benscat_bert$categoria_cepesp_bert[match(bens$id, benscat_bert$id)]
bens$categoria_cepesp_bert[bens$DS_BEM_CANDIDATO_CEPESP == "NENHUM BEM A DECLARAR"] <- "Nenhum bem a declarar"
# mudando a categoria "Imóveis" para Imóvel ou Propriedade
bens$categoria_cepesp_bert[bens$categoria_cepesp_bert == "Imóveis"] <- "Imóvel ou Propriedade"
bens$categoria_cepesp_manual[bens$categoria_cepesp_manual == "Imóveis"] <- "Imóvel ou Propriedade"
set.seed(10)
amostra <-
bens |>
select(ANO_ELEICAO,
DS_BEM_CANDIDATO,
DS_BEM_CANDIDATO_CEPESP,
DS_TIPO_BEM_CANDIDATO,
categoria_cepesp_manual,
categoria_cepesp_bert) |>
group_by(ANO_ELEICAO) |>
sample_n(100)
amostra$DS_BEM_CANDIDATO <- gsub("\\s+", " ", amostra$DS_BEM_CANDIDATO)
beep(3)
View(amostra)
set.seed(10)
amostra <-
bens |>
select(id,
ANO_ELEICAO,
DS_BEM_CANDIDATO,
DS_BEM_CANDIDATO_CEPESP,
DS_TIPO_BEM_CANDIDATO,
categoria_cepesp_manual,
categoria_cepesp_bert) |>
group_by(ANO_ELEICAO) |>
sample_n(100)
View(amostra)
View(bens[4029851,])
View(bens |> filter(DS_BEM_CANDIDATO == "IMOVEL - "))
